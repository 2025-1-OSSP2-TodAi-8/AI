Emotion Analysis Service â€” README

ìŒì„±(ì˜¤ë””ì˜¤)ê³¼ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì‚¬ìš©í•´ ê°ì •ì„ ë¶„ì„í•˜ê³ , ê³µê°í˜• ìš”ì•½ì„ ìƒì„±í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.
utils.py í•˜ë‚˜ë¡œ ë™ì‘í•˜ë©°, ëª¨ë¸/ê°€ì¤‘ì¹˜/ë² ì´ìŠ¤ë¼ì¸ ë²¡í„°ëŠ” Hugging Face Hubì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

êµ¬ì„± ìš”ì†Œ

STT: faster-whisper (large-v3)

í…ìŠ¤íŠ¸ ê°ì • ë¶„ë¥˜: HyukII/text-emotion-model (Transformers)

ì˜¤ë””ì˜¤ ê°ì • ë¶„ë¥˜: HyukII/audio-emotion-model

PyTorch ì»¤ìŠ¤í…€ ëª¨ë¸(model.py) + ê°€ì¤‘ì¹˜(pytorch_model.pth)

ë² ì´ìŠ¤ë¼ì¸ ë²¡í„°(baseline_mean_*.npy, baseline_std_*.npy) â€” (Xâˆ’mean)/(std+1eâˆ’8)

ìš”ì•½: OpenAI Chat Completions (gpt-4o-mini) â€“ ì„ íƒì 

ì„¤ì¹˜
# Python 3.9+
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu  # (GPUë©´ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ)
pip install transformers huggingface_hub safetensors
pip install faster-whisper librosa soundfile numpy
pip install openai  # ìš”ì•½ì„ ì“¸ ê²½ìš°


ê°œë°œ ì„œë²„ì—ì„œ í† í¬ë‚˜ì´ì € ê²½ê³ ë¥¼ ì¤„ì´ë ¤ë©´ í™˜ê²½ë³€ìˆ˜ ì„¤ì •:
TOKENIZERS_PARALLELISM=false

í™˜ê²½ ë³€ìˆ˜

OPENAI_API_KEY (ì„ íƒ): ìš”ì•½ ìƒì„±ì— í•„ìš”. ì—†ìœ¼ë©´ "summary": "(ìš”ì•½ ì‹¤íŒ¨) ..." í˜•íƒœë¡œ ë°˜í™˜ë¨.

í˜„ì¬ utils.pyëŠ” ì•„ë˜ ê³ ì •ëœ HF ë¦¬í¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

í…ìŠ¤íŠ¸: HyukII/text-emotion-model

ì˜¤ë””ì˜¤ : HyukII/audio-emotion-model

ì…ë ¥/ì¶œë ¥ í˜•ì‹
ì…ë ¥

ìŒì„± íŒŒì¼: .wav (ë‹¤ë¥¸ ìƒ˜í”Œë§ì´ì–´ë„ OK)

ë‚´ë¶€ì—ì„œ ensure_16k_mono()ë¡œ 16kHz mono ë³€í™˜ í›„ ì²˜ë¦¬

ì˜µì…˜ íŒŒë¼ë¯¸í„°:

gender: "MALE" ë˜ëŠ” "FEMALE" (ì˜¤ë””ì˜¤ ì •ê·œí™”ìš© ë² ì´ìŠ¤ë¼ì¸ ì„ íƒ)

lang: STT ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ "ko")

ì¶œë ¥(JSON)
{
  "summary": "ê³µê°í˜• í•œë‘ ë¬¸ì¥ ìš”ì•½(ë˜ëŠ” ìš”ì•½ ì‹¤íŒ¨ ë©”ì‹œì§€)",
  "emotion_analysis": [p0, p1, p2, p3, p4, p5]
}


emotion_analysisëŠ” í•œêµ­ì–´ 6ë¼ë²¨ ìˆœì„œë¡œ í™•ë¥ (0~1) ë°°ì—´ì„ ì œê³µí•©ë‹ˆë‹¤.
ë¼ë²¨ ìˆœì„œëŠ” í…ìŠ¤íŠ¸ ëª¨ë¸ì˜ id2labelì—ì„œ ê°€ì ¸ì˜¤ë©°, ê¸°ë³¸ì€:

['ê¸°ì¨','ë‹¹í™©','ë¶„ë…¸','ë¶ˆì•ˆ','ìƒì²˜','ìŠ¬í””']

ë™ì‘ íë¦„

STT: Whisperë¡œ ì—…ë¡œë“œëœ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬

í…ìŠ¤íŠ¸ ê°ì •: ë¬¸ì¥ ë‹¨ìœ„ ì¶”ë¡  â†’ ê°ì • ë¹„ìœ¨(%) ì‚°ì¶œ(KO 6ë¼ë²¨)

ì˜¤ë””ì˜¤ ê°ì •:

MFCC(13ch) ì¶”ì¶œ, ê¸¸ì´ 100 í”„ë ˆì„ìœ¼ë¡œ íŒ¨ë”©/ìë¥´ê¸° â†’ (100,13)

ì„±ë³„ë³„ ë² ì´ìŠ¤ë¼ì¸(mean/std)ì„ HFì—ì„œ .npyë¡œ ë‹¤ìš´ë¡œë“œ í›„ delta=(X-mean)/(std+1e-8)

í…ì„œ (1,13,100)ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ë””ì˜¤ ëª¨ë¸ ì¶”ë¡  â†’ EN 6ë¼ë²¨ í™•ë¥ 

ë¼ë²¨ ë§¤í•‘ & ìœµí•©:

KO(í…ìŠ¤íŠ¸) â†’ EN(ì˜¤ë””ì˜¤)ë¡œ íˆ¬ì˜ í›„, í…ìŠ¤íŠ¸ 0.7 + ì˜¤ë””ì˜¤ 0.3 ê°€ì¤‘í•©

ë‹¤ì‹œ EN â†’ KOë¡œ ê·¼ì‚¬ ì—­íˆ¬ì˜ â†’ ìµœì¢… KO í™•ë¥  ë²¡í„°

ìš”ì•½: ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ê³µê°í˜•ìœ¼ë¡œ 1â€“2ë¬¸ì¥ ìš”ì•½(ì˜µì…˜)

ë¹ ë¥¸ ì‚¬ìš© ì˜ˆì‹œ (Django view)
# views.py
from django.http import JsonResponse
from .utils import run_pipeline_on_uploaded_file

def analyze_view(request):
    if request.method != "POST" or "file" not in request.FILES:
        return JsonResponse({"error": "POST íŒŒì¼ ì—…ë¡œë“œ í•„ìš”"}, status=400)

    gender = request.POST.get("gender", "MALE")  # "MALE" | "FEMALE"
    lang = request.POST.get("lang", "ko")
    result = run_pipeline_on_uploaded_file(request.FILES["file"], gender=gender, lang=lang)
    return JsonResponse(result, json_dumps_params={"ensure_ascii": False})


curl í…ŒìŠ¤íŠ¸:

curl -X POST http://localhost:8000/api/diary/analyze \
  -F "file=@/path/to/sample.wav" \
  -F "gender=MALE" \
  -F "lang=ko"

ìŠ¤íƒ ë“œì–¼ë¡  í…ŒìŠ¤íŠ¸ (íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ)
from pathlib import Path
from types import SimpleNamespace
from .utils import run_pipeline_on_uploaded_file

class FileObj:
    def __init__(self, p): self.p=p
    def chunks(self, size=8192):
        with open(self.p, "rb") as f:
            while True:
                b=f.read(size)
                if not b: break
                yield b

wav = FileObj("/path/to/sample.wav")
res = run_pipeline_on_uploaded_file(wav, gender="FEMALE", lang="ko")
print(res)

ë‚´ë¶€ êµ¬í˜„ ìƒì„¸ (í•µì‹¬ í¬ì¸íŠ¸)

í…ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë”©

_tok = AutoTokenizer.from_pretrained("HyukII/text-emotion-model", use_fast=True)
_text_model = AutoModelForSequenceClassification.from_pretrained(...).eval()
# id2labelì€ config.json ìš°ì„ , ì—†ìœ¼ë©´ label_map.json ë‹¤ìš´ë¡œë“œ ì‚¬ìš©


ì˜¤ë””ì˜¤ ëª¨ë¸/ë¼ë²¨/ë² ì´ìŠ¤ë¼ì¸ ë¡œë”© (HF ì§í–‰)

from huggingface_hub import hf_hub_download
from importlib.machinery import SourceFileLoader

# labels.json ë‹¤ìš´ë¡œë“œ â†’ ë¦¬ìŠ¤íŠ¸
# model.py ë‹¤ìš´ë¡œë“œ â†’ SourceFileLoaderë¡œ PyTorchAudioModel ë¡œë“œ
# pytorch_model.pth ë‹¤ìš´ë¡œë“œ â†’ state_dict ë¡œë“œ
# baseline_mean|std_{male|female}.npy ë‹¤ìš´ë¡œë“œ â†’ delta ì •ê·œí™”


ì˜¤ë””ì˜¤ ì…ë ¥ & ì •ê·œí™”

MFCC: librosa.feature.mfcc(..., n_mfcc=13).T â†’ (T,13)

ê¸¸ì´ 100 í”„ë ˆì„ìœ¼ë¡œ íŒ¨ë”©/ìŠ¬ë¼ì´ìŠ¤ â†’ (100,13)

delta = (X - mean) / (std + 1e-8)

í…ì„œ (1,13,100)ë¡œ ë³€í™˜ í›„ ëª¨ë¸ ì¶”ë¡ 

ë¼ë²¨ ë§¤í•‘ í–‰ë ¬

EN ë¼ë²¨(ì˜¤ë””ì˜¤): labels.json (ê¸°ë³¸ ["ANGRY","SAD","DISGUST","HAPPY","FEAR","SURPRISE"])

KO ë¼ë²¨(í…ìŠ¤íŠ¸): ['ê¸°ì¨','ë‹¹í™©','ë¶„ë…¸','ë¶ˆì•ˆ','ìƒì²˜','ìŠ¬í””']

í…ìŠ¤íŠ¸ 0.7, ì˜¤ë””ì˜¤ 0.3 ë¹„ìœ¨ë¡œ ìœµí•© (ì›í•˜ë©´ fuse_text_audio(..., w_text, w_audio) ì¡°ì •)

ì£¼ì˜/íŒ

ìš”ì•½ ë¹„í™œì„±í™”: OPENAI_API_KEYê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì‹¤íŒ¨ ë©”ì‹œì§€ë¥¼ ë„£ê³  ë„˜ì–´ê°‘ë‹ˆë‹¤.
ìš´ì˜ì—ì„œ ìš”ì•½ì´ ê¼­ í•„ìš” ì—†ë‹¤ë©´ empathetic_summary()ë¥¼ ê±´ë„ˆë›°ë„ë¡ ìˆ˜ì •í•˜ì„¸ìš”.

GPU ì‚¬ìš©: torch.cuda.is_available()ì— ë”°ë¼ ìë™ ì„ íƒ. Whisper compute_typeë„ ìë™ ì¡°ì •(float16/int8).

ìºì‹œ: huggingface_hubëŠ” ë‹¤ìš´ë¡œë“œ íŒŒì¼ì„ ë¡œì»¬ ìºì‹œì— ë³´ê´€í•©ë‹ˆë‹¤(ì˜¤í”„ë¼ì¸ ì¬ì‚¬ìš© ê°€ëŠ¥).

ê²½ê³  ì–µì œ: TOKENIZERS_PARALLELISM=false ê¶Œì¥(Django dev serverì˜ autoreload/fork ì‹œ ê²½ê³  ë°©ì§€).

ë¼ë²¨ ìˆœì„œ ë¶ˆì¼ì¹˜ ì£¼ì˜:

ì˜¤ë””ì˜¤ labels.jsonê³¼ ë§¤í•‘ í–‰ë ¬(EN)ì˜ ìˆœì„œê°€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

í…ìŠ¤íŠ¸ ë¼ë²¨ ìˆœì„œëŠ” í…ìŠ¤íŠ¸ ëª¨ë¸ì˜ id2labelì— ë”°ë¦…ë‹ˆë‹¤.

ë¼ì´ì„ ìŠ¤ & í¬ë ˆë”§

ëª¨ë¸ê³¼ ì½”ë“œì˜ ë¼ì´ì„ ìŠ¤ëŠ” ê° HF ë¦¬í¬ì˜ README.md/LICENSEë¥¼ ë”°ë¦…ë‹ˆë‹¤.

Whisper ëª¨ë¸: faster-whisper

Transformers & HF Hub: ğŸ¤— Hugging Face
